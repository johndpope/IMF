# Loss function
loss:
  type: "vanilla"  # vanilla worked ok - https://wandb.ai/snoozie/IMF/runs/sa0i7gs6?nw=nwusersnoozie
  lpips_spatial: True
# Model parameters
model:
  latent_dim: 32
  base_channels: 64
  num_layers: 4
  use_resnet_feature: False
  use_mlgffn: False
  use_enhanced_generator: True
  use_skip: False
# Training parameters
training:
  use_r1_reg: True
  r1_gamma: 10
  r1_interval: 16

  use_multiscale_discriminator: True
  ada_augmentation: False
  ada_target_r_t: 0.6
  ada_kimg: 500
  ada_interval: 4

  use_ema: False
  ema_decay: 0.999
  style_mixing_prob: 0.9
  initial_noise_magnitude: 0.01
  final_noise_magnitude: 0.0001 

  initial_update_ratio: 1
  update_ratio_adjustment: 0.1
  
 

  initial_video_repeat: 5
  final_video_repeat: 2


  batch_size: 1 # need to redo emodataset to remove the cache npz - smaller numbers won't work... 
  num_epochs: 1000

  learning_rate_g: 1.0e-4 # Reduced learning rate for generator
  learning_rate_d: 4e-4

  gradient_accumulation_steps: 1

  lambda_perceptual: 10 # lambda perceptual = 10
  lambda_pixel: 5  # in paper lambda-pixel = 10 
  lambda_adv: 0.5 # 1 # Can sometimes lead to artifacts if weighted too heavily
  lambda_gp: 10  # Gradient penalty coefficient


  clip_grad_norm: 0.75  # Maximum norm for gradient clipping
 

  every_xref_frames: 16
  use_many_xrefs: False


  weight_decay: 1e-5

# Dataset parameters
dataset:
  # celeb-hq torrent https://github.com/johndpope/MegaPortrait-hack/tree/main/junk
  root_dir: "/media/oem/12TB/Downloads/CelebV-HQ/celebvhq/35666" # for overfitting M2Ohb0FAaJU_1.mp4 use https://github.com/johndpope/MegaPortrait-hack/tree/main/junk
  json_file: './data/overfit.json'  # Selena Gomez
  extracted_frames: "/mnt/gcs_bucket/media/oem/12TB/Downloads/CelebV-HQ/celebvhq/35666" # "/media/2TB/celebvhq/35666/images"
  
  # json_file: './data/celebvhq_info.json' # 35k

# Checkpointing
checkpoints:
  dir: "./checkpoints"
  interval: 10

# Logging and visualization
logging:
  sample_interval: 1
  sample_size: 1 # for images on wandb
  output_dir: "./samples"
  visualize_every: 100  # Visualize latent tokens every 100 batches
  print_model_details: False
  log_every: 100
  save_steps: 250
# Accelerator settings
accelerator:
  mixed_precision: "fp16"  # Options: "no", "fp16", "bf16"
  cpu: false
  num_processes: 1  # Set to more than 1 for multi-GPU training

# Discriminator parameters
discriminator:
  ndf: 64  # Number of filters in the first conv layer

# Optimizer parameters
optimizer:
  beta1: 0.0
  beta2: 0.999



