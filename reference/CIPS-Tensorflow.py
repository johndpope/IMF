from CIPS import CIPS
import argparse
from utils import *

def parse_args():
    desc = "Tensorflow implementation of CIPS"
    parser = argparse.ArgumentParser(description=desc)
    parser.add_argument('--phase', type=str, default='train', help='[train, test, draw]')
    parser.add_argument('--draw', type=str, default='uncurated', help='[uncurated, truncation_trick]')

    parser.add_argument('--dataset', type=str, default='FFHQ', help='dataset_name')

    parser.add_argument('--batch_size', type=int, default=4, help='The size of batch size')
    parser.add_argument('--print_freq', type=int, default=2000, help='The number of image_print_freq')
    parser.add_argument('--save_freq', type=int, default=10000, help='The number of ckpt_save_freq')

    parser.add_argument('--n_total_image', type=int, default=4800, help='The total iterations')
    parser.add_argument('--config', type=str, default='config-f', help='config-e or config-f')
    parser.add_argument('--lazy_regularization', type=str2bool, default=True, help='lazy_regularization')

    parser.add_argument('--img_size', type=int, default=256, help='The size of image')

    parser.add_argument('--n_test', type=int, default=10, help='The number of images generated by the test phase')

    parser.add_argument('--checkpoint_dir', type=str, default='checkpoint',
                        help='Directory name to save the checkpoints')
    parser.add_argument('--result_dir', type=str, default='results',
                        help='Directory name to save the generated images')
    parser.add_argument('--log_dir', type=str, default='logs',
                        help='Directory name to save training logs')
    parser.add_argument('--sample_dir', type=str, default='samples',
                        help='Directory name to save the samples on training')

    return check_args(parser.parse_args())


"""checking arguments"""
def check_args(args):
    # --checkpoint_dir
    check_folder(args.checkpoint_dir)

    # --result_dir
    check_folder(args.result_dir)

    # --result_dir
    check_folder(args.log_dir)

    # --sample_dir
    check_folder(args.sample_dir)

    # --batch_size
    try:
        assert args.batch_size >= 1
    except:
        print('batch size must be larger than or equal to one')

    return args

"""main"""
def main():

    args = vars(parse_args())

    # network params
    img_size = args['img_size']
    resolutions = [4, 8, 16, 32, 64, 128, 256, 512, 1024]
    if args['config'] == 'config-f':
        featuremaps = [512, 512, 512, 512, 512, 256, 128, 64, 32]  # config-f
    else:
        featuremaps = [512, 512, 512, 512, 256, 128, 64, 32, 16] # config-e
    train_resolutions, train_featuremaps = filter_resolutions_featuremaps(resolutions, featuremaps, img_size)
    g_params = {
        'z_dim': 512,
        'w_dim': 512,
        'labels_dim': 0,
        'n_mapping': 8,
        'resolutions': train_resolutions,
        'featuremaps': train_featuremaps,
        'w_ema_decay': 0.995,
        'style_mixing_prob': 0.9,
        'img_size': img_size,
        'hidden_size': 512,
    }
    d_params = {
        'labels_dim': 0,
        'resolutions': train_resolutions,
        'featuremaps': train_featuremaps,
    }

    strategy = tf.distribute.MirroredStrategy()
    NUM_GPUS = strategy.num_replicas_in_sync
    batch_size = args['batch_size'] * NUM_GPUS  # global batch size

    # training parameters
    training_parameters = {
        # global params
        **args,

        # network params
        'g_params': g_params,
        'd_params': d_params,

        # training params
        'g_opt': {'learning_rate': 0.002, 'beta1': 0.0, 'beta2': 0.99, 'epsilon': 1e-08, 'reg_interval': 4},
        'd_opt': {'learning_rate': 0.002, 'beta1': 0.0, 'beta2': 0.99, 'epsilon': 1e-08, 'reg_interval': 16},
        'batch_size': batch_size,
        'NUM_GPUS' : NUM_GPUS,
        'n_samples': 4,
    }

    # automatic_gpu_usage()
    with strategy.scope():
        gan = StyleGAN2(training_parameters, strategy)

        # build graph
        gan.build_model()


        if args['phase'] == 'train' :
            gan.train()
            print(" [*] Training finished!")

        if args['phase'] == 'test':
            gan.test()
            print(" [*] Test finished!")

        if args['phase'] == 'draw':

            if args['draw'] == 'truncation_trick':

                gan.draw_truncation_trick_figure()

                print(" [*] Truncation_trick finished!")


            else:
                gan.draw_uncurated_result_figure()

                print(" [*] Un-curated finished!")



if __name__ == '__main__':
    main()
from cuda.upfirdn_2d import *
from cuda.fused_bias_act import fused_bias_act

##################################################################################
# Layers
##################################################################################

class Conv2D(tf.keras.layers.Layer):
    def __init__(self, fmaps, kernel, resample_kernel, up, down, gain, lrmul, **kwargs):
        super(Conv2D, self).__init__(**kwargs)
        self.fmaps = fmaps
        self.kernel = kernel
        self.gain = gain
        self.lrmul = lrmul
        self.up = up
        self.down = down

        self.k, self.pad0, self.pad1 = compute_paddings(resample_kernel, self.kernel, up, down, is_conv=True)

    def build(self, input_shape):
        weight_shape = [self.kernel, self.kernel, input_shape[1], self.fmaps]
        init_std, self.runtime_coef = compute_runtime_coef(weight_shape, self.gain, self.lrmul)

        # [kernel, kernel, fmaps_in, fmaps_out]
        w_init = tf.random.normal(shape=weight_shape, mean=0.0, stddev=init_std)
        self.w = tf.Variable(w_init, name='w', trainable=True)

    def call(self, inputs, training=None, mask=None):
        x = inputs
        w = self.runtime_coef * self.w

        # actual conv
        if self.up:
            x = upsample_conv_2d(x, w, self.kernel, self.kernel, self.pad0, self.pad1, self.k)
        elif self.down:
            x = conv_downsample_2d(x, w, self.kernel, self.kernel, self.pad0, self.pad1, self.k)
        else:
            x = tf.nn.conv2d(x, w, data_format='NCHW', strides=[1, 1, 1, 1], padding='SAME')
        return x

class ModulatedConv2D(tf.keras.layers.Layer):
    def __init__(self, fmaps, style_fmaps, kernel, resample_kernel, up, down, demodulate, fused_modconv, gain, lrmul, **kwargs):
        super(ModulatedConv2D, self).__init__(**kwargs)
        assert not (up and down)

        self.fmaps = fmaps
        self.style_fmaps = style_fmaps
        self.kernel = kernel
        self.demodulate = demodulate
        self.up = up
        self.down = down
        self.fused_modconv = fused_modconv
        self.gain = gain
        self.lrmul = lrmul

        self.k, self.pad0, self.pad1 = compute_paddings(resample_kernel, self.kernel, up, down, is_conv=True)

        # self.factor = 2
        self.mod_dense = Dense(self.style_fmaps, gain=1.0, lrmul=1.0, name='mod_dense')
        self.mod_bias = BiasAct(lrmul=1.0, act='linear', name='mod_bias')

    def build(self, input_shape):
        x_shape, w_shape = input_shape[0], input_shape[1]
        in_fmaps = x_shape[1]
        weight_shape = [self.kernel, self.kernel, in_fmaps, self.fmaps]
        init_std, self.runtime_coef = compute_runtime_coef(weight_shape, self.gain, self.lrmul)

        # [kkIO]
        w_init = tf.random.normal(shape=weight_shape, mean=0.0, stddev=init_std)
        self.w = tf.Variable(w_init, name='w', trainable=True)

    def scale_conv_weights(self, w):
        # convolution kernel weights for fused conv
        weight = self.runtime_coef * self.w  # [kkIO]
        weight = weight[np.newaxis]  # [BkkIO]

        # modulation
        style = self.mod_dense(w)  # [BI]
        style = self.mod_bias(style) + 1.0  # [BI]
        weight *= style[:, np.newaxis, np.newaxis, :, np.newaxis]  # [BkkIO]

        # demodulation
        d = None
        if self.demodulate:
            d = tf.math.rsqrt(tf.reduce_sum(tf.square(weight), axis=[1, 2, 3]) + 1e-8)  # [BO]
            weight *= d[:, np.newaxis, np.newaxis, np.newaxis, :]  # [BkkIO]

        return weight, style, d

    def call(self, inputs, training=None, mask=None):
        x, y = inputs
        # height, width = tf.shape(x)[2], tf.shape(x)[3]

        # prepare weights: [BkkIO] Introduce minibatch dimension
        # prepare convoultuon kernel weights
        weight, style, d = self.scale_conv_weights(y)

        if self.fused_modconv:
            # Fused => reshape minibatch to convolution groups
            x = tf.reshape(x, [1, -1, x.shape[2], x.shape[3]])

            # weight: reshape, prepare for fused operation
            new_weight_shape = [tf.shape(weight)[1], tf.shape(weight)[2], tf.shape(weight)[3], -1]  # [kkI(BO)]
            weight = tf.transpose(weight, [1, 2, 3, 0, 4])  # [kkIBO]
            weight = tf.reshape(weight, shape=new_weight_shape)  # [kkI(BO)]
        else:
            # [BIhw] Not fused => scale input activations
            x *= style[:, :, tf.newaxis, tf.newaxis]

        # Convolution with optional up/downsampling.
        if self.up:
            x = upsample_conv_2d(x, weight, self.kernel, self.kernel, self.pad0, self.pad1, self.k)
        elif self.down:
            x = conv_downsample_2d(x, weight, self.kernel, self.kernel, self.pad0, self.pad1, self.k)
        else:
            x = tf.nn.conv2d(x, weight, data_format='NCHW', strides=[1, 1, 1, 1], padding='SAME')

        # Reshape/scale output
        if self.fused_modconv:
            # Fused => reshape convolution groups back to minibatch
            x_shape = tf.shape(x)
            x = tf.reshape(x, [-1, self.fmaps, x_shape[2], x_shape[3]])
        elif self.demodulate:
            # [BOhw] Not fused => scale output activations
            x *= d[:, :, tf.newaxis, tf.newaxis]

        return x


class Dense(tf.keras.layers.Layer):
    def __init__(self, fmaps, gain=1.0, lrmul=1.0, **kwargs):
        super(Dense, self).__init__(**kwargs)
        self.fmaps = fmaps
        self.gain = gain
        self.lrmul = lrmul

    def build(self, input_shape):
        fan_in = tf.reduce_prod(input_shape[1:])
        weight_shape = [fan_in, self.fmaps]
        init_std, self.runtime_coef = compute_runtime_coef(weight_shape, self.gain, self.lrmul)

        w_init = tf.random.normal(shape=weight_shape, mean=0.0, stddev=init_std)
        self.w = tf.Variable(w_init, name='w', trainable=True)

    def call(self, inputs, training=None, mask=None):
        weight = self.runtime_coef * self.w

        c = tf.reduce_prod(tf.shape(inputs)[1:])
        x = tf.reshape(inputs, shape=[-1, c])
        x = tf.matmul(x, weight)
        return x

class LabelEmbedding(tf.keras.layers.Layer):
    def __init__(self, embed_dim, **kwargs):
        super(LabelEmbedding, self).__init__(**kwargs)
        self.embed_dim = embed_dim

    def build(self, input_shape):
        weight_shape = [input_shape[1], self.embed_dim]
        # tf 1.15 mean(0.0), std(1.0) default value of tf.initializers.random_normal()
        w_init = tf.random.normal(shape=weight_shape, mean=0.0, stddev=1.0)
        self.w = tf.Variable(w_init, name='w', trainable=True)

    def call(self, inputs, training=None, mask=None):
        x = tf.matmul(inputs, self.w)
        return x

##################################################################################
# etc
##################################################################################
class PixelNorm(tf.keras.layers.Layer):
    def __init__(self, **kwargs):
        super(PixelNorm, self).__init__(**kwargs)

    def call(self, inputs, training=None, mask=None):
        x = inputs * tf.math.rsqrt(tf.reduce_mean(tf.square(inputs), axis=1, keepdims=True) + 1e-8)
        return x

class BiasAct(tf.keras.layers.Layer):
    def __init__(self, lrmul, act, **kwargs):
        super(BiasAct, self).__init__(**kwargs)
        self.lrmul = lrmul
        self.act = act

    def build(self, input_shape):
        b_init = tf.zeros(shape=(input_shape[1],), dtype=tf.float32)
        self.b = tf.Variable(b_init, name='b', trainable=True)

    def call(self, inputs, training=None, mask=None):
        b = self.lrmul * self.b
        x = fused_bias_act(inputs, b=b, act=self.act, alpha=None, gain=None)
        return x

class Noise(tf.keras.layers.Layer):
    def __init__(self, **kwargs):
        super(Noise, self).__init__(**kwargs)

    def build(self, input_shape):
        self.noise_strength = tf.Variable(initial_value=0.0, dtype=tf.float32, trainable=True, name='w')


    def call(self, inputs, noise=None, training=None, mask=None):
        x_shape = tf.shape(inputs)

        # noise: [1, 1, x_shape[2], x_shape[3]] or None
        if noise is None:
            noise = tf.random.normal(shape=(x_shape[0], 1, x_shape[2], x_shape[3]), dtype=tf.float32)

        x = inputs + noise * self.noise_strength
        return x

class MinibatchStd(tf.keras.layers.Layer):
    def __init__(self, group_size, num_new_features, **kwargs):
        super(MinibatchStd, self).__init__(**kwargs)
        self.group_size = group_size
        self.num_new_features = num_new_features

    def call(self, inputs, training=None, mask=None):
        s = tf.shape(inputs)
        group_size = tf.minimum(self.group_size, s[0])

        y = tf.reshape(inputs, [group_size, -1, self.num_new_features, s[1] // self.num_new_features, s[2], s[3]])
        y = tf.cast(y, tf.float32)
        y -= tf.reduce_mean(y, axis=0, keepdims=True)
        y = tf.reduce_mean(tf.square(y), axis=0)
        y = tf.sqrt(y + 1e-8)
        y = tf.reduce_mean(y, axis=[2, 3, 4], keepdims=True)
        y = tf.reduce_mean(y, axis=[2])
        y = tf.cast(y, inputs.dtype)
        y = tf.tile(y, [group_size, 1, s[2], s[3]])

        x = tf.concat([inputs, y], axis=1)
        return x

def compute_runtime_coef(weight_shape, gain, lrmul):
    fan_in = tf.reduce_prod(weight_shape[:-1])  # [kernel, kernel, fmaps_in, fmaps_out] or [in, out]
    fan_in = tf.cast(fan_in, dtype=tf.float32)
    he_std = gain / tf.sqrt(fan_in)
    init_std = 1.0 / lrmul
    runtime_coef = he_std * lrmul
    return init_std, runtime_coef

def lerp(a, b, t):
    out = a + (b - a) * t
    return out

def lerp_clip(a, b, t):
    out = a + (b - a) * tf.clip_by_value(t, 0.0, 1.0)
    return out


def get_coords(batch_size, height, width):

    x = tf.linspace(-1, 1, width)
    x = tf.reshape(x, shape=[1, 1, width, 1])
    x = tf.tile(x, multiples=[batch_size, width, 1, 1])

    y = tf.linspace(-1, 1, height)
    y = tf.reshape(y, shape=[1, height, 1, 1])
    y = tf.tile(y, multiples=[batch_size, 1, height, 1])

    coords = tf.concat([x, y], axis=-1)
    coords = tf.transpose(coords, perm=[0, 3, 1, 2])
    coords = tf.cast(coords, tf.float32)

    return coords

def grid_sample_tf(img, coords, align_corners=False, padding='border'):
    """

    :param img: [B, C, H, W]
    :param coords: [B, C, H, W]
    :return: [B, C, H, W]
    """
    def get_pixel_value(img, x, y):
        """
        Utility function to get pixel value for coordinate
        vectors x and y from a  4D tensor image.
        Input
        -----
        - img: tensor of shape (B, H, W, C)
        - x: flattened tensor of shape (B*H*W,)
        - y: flattened tensor of shape (B*H*W,)
        Returns
        -------
        - output: tensor of shape (B, H, W, C)
        """
        shape = tf.shape(x)
        batch_size = shape[0]
        height = shape[1]
        width = shape[2]

        batch_idx = tf.range(0, batch_size)
        batch_idx = tf.reshape(batch_idx, (batch_size, 1, 1))
        b = tf.tile(batch_idx, (1, height, width))

        indices = tf.stack([b, y, x], 3)

        return tf.gather_nd(img, indices)

    # rescale x and y to [0, W-1/H-1]
    img = tf.transpose(img, perm=[0, 2, 3, 1]) # -> [N, H, W, C]
    coords = tf.transpose(coords, perm=[0, 2, 3, 1]) # -> [N, H, W, C]

    x, y = coords[:, ..., 0], coords[:, ..., 1]
    x = tf.cast(x, 'float32')
    y = tf.cast(y, 'float32')

    side = tf.cast(tf.shape(img)[1], tf.int32)
    side_f = tf.cast(side, tf.float32)

    if align_corners:
        x = ((x + 1) / 2) * (side_f - 1)
        y = ((y + 1) / 2) * (side_f - 1)
    else:
        x = 0.5 * ((x + 1.0) * side_f - 1)
        y = 0.5 * ((y + 1.0) * side_f - 1)

    if padding == 'border':
        x = tf.clip_by_value(x, 0, side_f - 1)
        y = tf.clip_by_value(y, 0, side_f - 1)

    # -------------- Changes above --------------------
    # grab 4 nearest corner points for each (x_i, y_i)
    x0 = tf.floor(x)
    x1 = x0 + 1
    y0 = tf.floor(y)
    y1 = y0 + 1

    # recast as float for delta calculation
    x0 = tf.cast(x0, 'float32')
    x1 = tf.cast(x1, 'float32')
    y0 = tf.cast(y0, 'float32')
    y1 = tf.cast(y1, 'float32')

    # calculate deltas
    wa = (x1 - x) * (y1 - y)
    wb = (x1 - x) * (y - y0)
    wc = (x - x0) * (y1 - y)
    wd = (x - x0) * (y - y0)

    # recast as int for img boundaries
    x0 = tf.cast(x0, 'int32')
    x1 = tf.cast(x1, 'int32')
    y0 = tf.cast(y0, 'int32')
    y1 = tf.cast(y1, 'int32')

    # clip to range [0, H-1/W-1] to not violate img boundaries
    x0 = tf.clip_by_value(x0, 0, side-1)
    x1 = tf.clip_by_value(x1, 0, side-1)
    y0 = tf.clip_by_value(y0, 0, side-1)
    y1 = tf.clip_by_value(y1, 0, side-1)

    # get pixel value at corner coords
    Ia = get_pixel_value(img, x0, y0)
    Ib = get_pixel_value(img, x0, y1)
    Ic = get_pixel_value(img, x1, y0)
    Id = get_pixel_value(img, x1, y1)

    # add dimension for addition
    wa = tf.expand_dims(wa, axis=3)
    wb = tf.expand_dims(wb, axis=3)
    wc = tf.expand_dims(wc, axis=3)
    wd = tf.expand_dims(wd, axis=3)

    # compute output
    out = wa * Ia + wb * Ib + wc * Ic + wd * Id # [N, H, W, C]
    out = tf.transpose(out, perm=[0, 3, 1, 2])

    return out

def torch_normalization(x):
    x /= 255.

    r, g, b = tf.split(axis=-1, num_or_size_splits=3, value=x)

    mean = [0.485, 0.456, 0.406]
    std = [0.229, 0.224, 0.225]

    x = tf.concat(axis=-1, values=[
        (r - mean[0]) / std[0],
        (g - mean[1]) / std[1],
        (b - mean[2]) / std[2]
    ])

    return x


def inception_processing(filename):
    x = tf.io.read_file(filename)
    img = tf.image.decode_jpeg(x, channels=3, dct_method='INTEGER_ACCURATE')
    img = tf.image.resize(img, [256, 256], antialias=True, method=tf.image.ResizeMethod.BICUBIC)
    img = tf.image.resize(img, [299, 299], antialias=True, method=tf.image.ResizeMethod.BICUBIC)

    img = torch_normalization(img)
    # img = tf.transpose(img, [2, 0, 1])
    return img
import numpy as np
import os
import cv2

import tensorflow as tf
from glob import glob

class Image_data:

    def __init__(self, img_size, z_dim, labels_dim, dataset_path):
        self.img_size = img_size
        self.z_dim = z_dim
        self.labels_dim = labels_dim
        self.dataset_path = dataset_path


    def image_processing(self, filename):

        x = tf.io.read_file(filename)
        x_decode = tf.image.decode_jpeg(x, channels=3, dct_method='INTEGER_ACCURATE')
        img = tf.image.resize(x_decode, [self.img_size, self.img_size], antialias=True, method=tf.image.ResizeMethod.BICUBIC)
        img = preprocess_fit_train_image(img)

        latent = tf.random.normal(shape=(self.z_dim,), dtype=tf.float32)
        labels = tf.random.normal((self.labels_dim,), dtype=tf.float32)

        return img, latent, labels

    def preprocess(self):

        self.train_images = glob(os.path.join(self.dataset_path, '*.png')) + glob(os.path.join(self.dataset_path, '*.jpg'))

def adjust_dynamic_range(images, range_in, range_out, out_dtype):
    scale = (range_out[1] - range_out[0]) / (range_in[1] - range_in[0])
    bias = range_out[0] - range_in[0] * scale
    images = images * scale + bias
    images = tf.clip_by_value(images, range_out[0], range_out[1])
    images = tf.cast(images, dtype=out_dtype)
    return images

def random_flip_left_right(images):
    s = tf.shape(images)
    mask = tf.random.uniform([1, 1, 1], 0.0, 1.0)
    mask = tf.tile(mask, [s[0], s[1], s[2]]) # [h, w, c]
    images = tf.where(mask < 0.5, images, tf.reverse(images, axis=[1]))
    return images

def preprocess_fit_train_image(images):
    images = adjust_dynamic_range(images, range_in=(0.0, 255.0), range_out=(-1.0, 1.0), out_dtype=tf.dtypes.float32)
    images = random_flip_left_right(images)
    images = tf.transpose(images, [2, 0, 1])

    return images

def preprocess_image(images):
    images = adjust_dynamic_range(images, range_in=(0.0, 255.0), range_out=(-1.0, 1.0), out_dtype=tf.dtypes.float32)
    images = tf.transpose(images, [2, 0, 1])

    return images

def postprocess_images(images):
    images = adjust_dynamic_range(images, range_in=(-1.0, 1.0), range_out=(0.0, 255.0), out_dtype=tf.dtypes.float32)
    images = tf.transpose(images, [0, 2, 3, 1])
    images = tf.cast(images, dtype=tf.dtypes.uint8)
    return images

def merge_batch_images(images, res, rows, cols):
    batch_size = images.shape[0]
    assert rows * cols == batch_size
    canvas = np.zeros(shape=[res * rows, res * cols, 3], dtype=np.uint8)
    for row in range(rows):
        y_start = row * res
        for col in range(cols):
            x_start = col * res
            index = col + row * cols
            canvas[y_start:y_start + res, x_start:x_start + res, :] = images[index, :, :, :]
    return canvas

def load_images(image_path, img_width, img_height, img_channel):

    # from PIL import Image
    if img_channel == 1 :
        img = cv2.imread(image_path, flags=cv2.IMREAD_GRAYSCALE)
    else :
        img = cv2.imread(image_path, flags=cv2.IMREAD_COLOR)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # img = cv2.resize(img, dsize=(img_width, img_height))
    img = tf.image.resize(img, [img_height, img_width], antialias=True, method=tf.image.ResizeMethod.BICUBIC)
    img = preprocess_image(img)

    if img_channel == 1 :
        img = np.expand_dims(img, axis=0)
        img = np.expand_dims(img, axis=-1)
    else :
        img = np.expand_dims(img, axis=0)

    return img

def save_images(images, size, image_path):
    # size = [height, width]
    return imsave(postprocess_images(images), size, image_path)

def imsave(images, size, path):
    images = merge(images, size)
    images = cv2.cvtColor(images.astype('uint8'), cv2.COLOR_RGB2BGR)

    return cv2.imwrite(path, images)

def merge(images, size):
    h, w = images.shape[1], images.shape[2]
    img = np.zeros((h * size[0], w * size[1], 3))
    for idx, image in enumerate(images):
        i = idx % size[1]
        j = idx // size[1]
        img[h*j:h*(j+1), w*i:w*(i+1), :] = image

    return img

def str2bool(x):
    return x.lower() in ('true')

def check_folder(log_dir):
    if not os.path.exists(log_dir):
        os.makedirs(log_dir)
    return log_dir

def filter_resolutions_featuremaps(resolutions, featuremaps, res):
    index = resolutions.index(res)
    filtered_resolutions = resolutions[:index + 1]
    filtered_featuremaps = featuremaps[:index + 1]
    return filtered_resolutions, filtered_featuremaps

def pytorch_xavier_weight_factor(gain=0.02) :

    factor = gain * gain
    mode = 'fan_avg'

    return factor, mode

def pytorch_kaiming_weight_factor(a=0.0, activation_function='relu') :

    if activation_function == 'relu' :
        gain = np.sqrt(2.0)
    elif activation_function == 'leaky_relu' :
        gain = np.sqrt(2.0 / (1 + a ** 2))
    elif activation_function =='tanh' :
        gain = 5.0 / 3
    else :
        gain = 1.0

    factor = gain * gain
    mode = 'fan_in'

    return factor, mode

def automatic_gpu_usage() :
    gpus = tf.config.experimental.list_physical_devices('GPU')
    if gpus:
        try:
            # Currently, memory growth needs to be the same across GPUs
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
            logical_gpus = tf.config.experimental.list_logical_devices('GPU')
            print(len(gpus), "Physical GPUs,", len(logical_gpus), "Logical GPUs")
        except RuntimeError as e:
            # Memory growth must be set before GPUs have been initialized
            print(e)

def multiple_gpu_usage():
    gpus = tf.config.experimental.list_physical_devices('GPU')
    if gpus:
        # Create 2 virtual GPUs with 1GB memory each
        try:
            tf.config.experimental.set_virtual_device_configuration(
                gpus[0],
                [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096),
                 tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])
            logical_gpus = tf.config.experimental.list_logical_devices('GPU')
            print(len(gpus), "Physical GPU,", len(logical_gpus), "Logical GPUs")
        except RuntimeError as e:
            # Virtual devices must be set before GPUs have been initialized
            print(e)

def get_batch_sizes(gpu_num) :
    from collections import OrderedDict
    # batch size for each gpu

    if gpu_num == 1:
        x = OrderedDict([(4, 256), (8, 256), (16, 128), (32, 64), (64, 32), (128, 16), (256, 8), (512, 4), (1024, 4)])

    elif gpu_num == 2 or gpu_num == 3:
        x = OrderedDict([(4, 128), (8, 128), (16, 64), (32, 32), (64, 16), (128, 8), (256, 4), (512, 4), (1024, 4)])

    elif gpu_num == 4 or gpu_num == 5 or gpu_num == 6:
        x = OrderedDict([(4, 64), (8, 64), (16, 32), (32, 16), (64, 8), (128, 4), (256, 4), (512, 4), (1024, 4)])

    elif gpu_num == 7 or gpu_num == 8 or gpu_num == 9:
        x = OrderedDict([(4, 32), (8, 32), (16, 16), (32, 8), (64, 4), (128, 4), (256, 4), (512, 4), (1024, 4)])

    else:  # >= 10
        x = OrderedDict([(4, 16), (8, 16), (16, 8), (32, 4), (64, 2), (128, 2), (256, 2), (512, 2), (1024, 2)])

    return x

def multi_gpu_loss(x, global_batch_size):
    ndim = len(x.shape)
    no_batch_axis = list(range(1, ndim))
    x = tf.reduce_mean(x, axis=no_batch_axis)
    x = tf.reduce_sum(x) / global_batch_size

    return x

class EasyDict(dict):
    from typing import Any
    """Convenience class that behaves like a dict but allows access with the attribute syntax."""

    def __getattr__(self, name: str) -> Any:
        try:
            return self[name]
        except KeyError:
            raise AttributeError(name)

    def __setattr__(self, name: str, value: Any) -> None:
        self[name] = value

    def __delattr__(self, name: str) -> None:
        del self[name]
from layers import *
from tensorflow.keras import Sequential

##################################################################################
# CIPS Generator Networks
##################################################################################

class CIPSskip(tf.keras.Model):
    def __init__(self, g_params, **kwargs):
        super(CIPSskip, self).__init__(**kwargs)

        self.size = g_params['img_size']
        self.hidden_size = g_params['hidden_size']
        self.w_dim = g_params['w_dim']
        self.labels_dim = g_params['labels_dim']
        self.featuremaps = g_params['featuremaps']
        self.n_mapping = g_params['n_mapping']

        self.lff = LFF(self.hidden_size)
        self.emb = ConstantInput(self.hidden_size, self.size)

        self.convs = []
        self.to_rgbs = []
        self.log_size = int(np.log2(self.size))

        self.n_intermediate = self.log_size - 1
        self.to_rgb_stride = 2

        if self.labels_dim > 0:
            self.labels_embedding = LabelEmbedding(embed_dim=self.w_dim, name='labels_embedding')

        self.conv1 = StyledConv(fmaps=self.featuremaps[0], style_fmaps=self.featuremaps[0]*2, kernel=1, resample_kernel=[1, 3, 3, 1])

        for i in range(self.log_size - 1):
            fmaps = self.featuremaps[i]
            style_fmaps2 = fmaps
            if i == 0:
                style_fmaps = fmaps
            else:
                style_fmaps = self.featuremaps[i-1]
            self.convs.append(StyledConv(fmaps=fmaps, style_fmaps=style_fmaps, kernel=1, resample_kernel=[1, 3, 3, 1]))
            self.convs.append(StyledConv(fmaps=fmaps, style_fmaps=style_fmaps2, kernel=1, resample_kernel=[1, 3, 3, 1]))
            self.to_rgbs.append(ToRGB(fmaps=style_fmaps2))

        self.mapping_layers = [PixelNorm()]

        for i in range(self.n_mapping):
            self.mapping_layers.append(Dense(fmaps=self.w_dim))

        self.mapping_layers = Sequential(self.mapping_layers)

    def build(self, input_shape):
        self.coords = get_coords(batch_size=input_shape[0][0], height=self.size, width=self.size)

    @tf.function
    def set_as_moving_average_of(self, src_net, beta=0.99, beta_nontrainable=0.0):
        for cw, sw in zip(self.weights, src_net.weights):
            assert sw.shape == cw.shape

            if 'w_avg' in cw.name:
                cw.assign(lerp(sw, cw, beta_nontrainable))
            else:
                cw.assign(lerp(sw, cw, beta))
        return

    def call(self, inputs, truncation_psi=1.0, ret_w=True, input_is_latent=False, training=None, mask=None):
        latent, labels = inputs
        if truncation_psi < 1:
            truncation_latent = tf.reduce_mean(tf.random.normal(shape=[4096, self.w_dim]), axis=0, keepdims=True)
            latent = truncation_latent + truncation_psi * (latent - truncation_latent)

        # embed label if any
        if self.labels_dim > 0:
            y = self.labels_embedding(labels)
            latent = tf.concat([latent, y], axis=1)

        if not input_is_latent:
            latent = self.mapping_layers(latent)
        fourier = self.lff(self.coords)

        batch_size, _, height, width = self.coords.shape

        if training and width == height == self.size:
            coord_emb = self.emb(fourier)
        else:
            coord_emb = self.emb(fourier)
            coord_emb = grid_sample_tf(coord_emb, self.coords)

        x = tf.concat([fourier, coord_emb], axis=1) # channel concat
        rgb = None
        x = self.conv1([x, latent])
        for i in range(self.n_intermediate):
            for j in range(self.to_rgb_stride):
                x = self.convs[i*self.to_rgb_stride + j]([x, latent])

            rgb = self.to_rgbs[i]([x, latent], skip=rgb)

        if ret_w:
            return rgb, latent
        else:
            return rgb

##################################################################################
# Discriminator Networks
##################################################################################
class Discriminator(tf.keras.Model):
    def __init__(self, d_params, **kwargs):
        super(Discriminator, self).__init__(**kwargs)
        # discriminator's (resolutions and featuremaps) are reversed against generator's
        self.labels_dim = d_params['labels_dim']
        self.r_resolutions = d_params['resolutions'][::-1]
        self.r_featuremaps = d_params['featuremaps'][::-1]

        # stack discriminator blocks
        res0, n_f0 = self.r_resolutions[0], self.r_featuremaps[0]
        self.initial_fromrgb = FromRGB(fmaps=n_f0, name='{:d}x{:d}/FromRGB'.format(res0, res0))
        self.blocks = []

        for index, (res0, n_f0) in enumerate(zip(self.r_resolutions[:-1], self.r_featuremaps[:-1])):
            n_f1 = self.r_featuremaps[index + 1]
            self.blocks.append(DiscriminatorBlock(n_f0=n_f0, n_f1=n_f1, name='{:d}x{:d}'.format(res0, res0)))

        # set last discriminator block
        res = self.r_resolutions[-1]
        n_f0, n_f1 = self.r_featuremaps[-2], self.r_featuremaps[-1]
        self.last_block = DiscriminatorLastBlock(n_f0, n_f1, name='{:d}x{:d}'.format(res, res))

        # set last dense layer
        self.last_dense = Dense(max(self.labels_dim, 1), gain=1.0, lrmul=1.0, name='last_dense')
        self.last_bias = BiasAct(lrmul=1.0, act='linear', name='last_bias')



    # @ tf.function
    def call(self, inputs, training=None, mask=None):
        images, labels = inputs

        x = self.initial_fromrgb(images)
        for block in self.blocks:
            x = block(x)

        x = self.last_block(x)

        logit = self.last_dense(x)
        logit = self.last_bias(logit)

        if self.labels_dim > 0:
            logit = tf.reduce_sum(logit * labels, axis=1, keepdims=True)

        scores_out = logit

        return scores_out
from utils import *
import time
from tensorflow.python.data.experimental import AUTOTUNE
from networks import *
import PIL.Image
import scipy
import pickle
automatic_gpu_usage()

class Inception_V3(tf.keras.Model):
    def __init__(self, name='Inception_V3'):
        super(Inception_V3, self).__init__(name=name)

        # tf.keras.backend.image_data_format = 'channels_first'
        self.inception_v3_preprocess = tf.keras.applications.inception_v3.preprocess_input
        self.inception_v3 = tf.keras.applications.inception_v3.InceptionV3(weights='imagenet', include_top=False, pooling='avg')
        self.inception_v3.trainable = False

    def torch_normalization(self, x):
        x /= 255.

        r, g, b = tf.split(axis=-1, num_or_size_splits=3, value=x)

        mean = [0.485, 0.456, 0.406]
        std = [0.229, 0.224, 0.225]

        x = tf.concat(axis=-1, values=[
            (r - mean[0]) / std[0],
            (g - mean[1]) / std[1],
            (b - mean[2]) / std[2]
        ])

        return x

    # @tf.function
    def call(self, x, training=False, mask=None):
        # x = self.torch_normalization(x)
        x = self.inception_v3(x, training=training)

        return x

    def inference_feat(self, x, training=False):
        inception_real_img = adjust_dynamic_range(x, range_in=(-1.0, 1.0), range_out=(0.0, 255.0), out_dtype=tf.float32)
        inception_real_img = tf.image.resize(inception_real_img, [299, 299], antialias=True, method=tf.image.ResizeMethod.BICUBIC)
        inception_real_img = self.torch_normalization(inception_real_img)

        inception_feat = self.inception_v3(inception_real_img, training=training)

        return inception_feat

class CIPS():
    def __init__(self, t_params, strategy):
        super(CIPS, self).__init__()

        self.model_name = 'CIPS'
        self.phase = t_params['phase']
        self.checkpoint_dir = t_params['checkpoint_dir']
        self.result_dir = t_params['result_dir']
        self.log_dir = t_params['log_dir']
        self.sample_dir = t_params['sample_dir']
        self.dataset_name = t_params['dataset']
        self.config = t_params['config']

        self.n_total_image = t_params['n_total_image'] * 1000

        self.strategy = strategy
        self.batch_size = t_params['batch_size']
        self.each_batch_size = t_params['batch_size'] // t_params['NUM_GPUS']

        self.NUM_GPUS = t_params['NUM_GPUS']
        self.iteration = self.n_total_image // self.batch_size

        self.n_samples = min(t_params['batch_size'], t_params['n_samples'])
        self.n_test = t_params['n_test']
        self.img_size = t_params['img_size']

        self.log_template = 'step [{}/{}]: elapsed: {:.2f}s, d_loss: {:.3f}, g_loss: {:.3f}, r1_reg: {:.3f}, pl_reg: {:.3f}, fid: {:.2f}, best_fid: {:.2f}, best_fid_iter: {}'

        self.lazy_regularization = t_params['lazy_regularization']
        self.print_freq = t_params['print_freq']
        self.save_freq = t_params['save_freq']

        self.r1_gamma = 10.0

        # setup optimizer params
        self.g_params = t_params['g_params']

        self.d_params = t_params['d_params']
        self.g_opt = t_params['g_opt']
        self.d_opt = t_params['d_opt']
        self.g_opt = self.set_optimizer_params(self.g_opt)
        self.d_opt = self.set_optimizer_params(self.d_opt)

        self.pl_minibatch_shrink = 2
        self.pl_decay = 0.01
        self.pl_weight = float(self.pl_minibatch_shrink)
        self.pl_denorm = tf.math.rsqrt(float(self.img_size) * float(self.img_size))
        self.pl_mean = tf.Variable(initial_value=0.0, name='pl_mean', trainable=False,
                                   synchronization=tf.VariableSynchronization.ON_READ,
                                   aggregation=tf.VariableAggregation.ONLY_FIRST_REPLICA
                                   )

        self.sample_dir = os.path.join(self.sample_dir, self.model_dir)
        check_folder(self.sample_dir)

        self.checkpoint_dir = os.path.join(self.checkpoint_dir, self.model_dir)
        check_folder(self.checkpoint_dir)

        self.log_dir = os.path.join(self.log_dir, self.model_dir)
        check_folder(self.log_dir)


        dataset_path = './dataset'
        self.dataset_path = os.path.join(dataset_path, self.dataset_name)

        print(self.dataset_path)

        if os.path.exists('{}_mu_cov.pickle'.format(self.dataset_name)):
            with open('{}_mu_cov.pickle'.format(self.dataset_name), 'rb') as f:
                self.real_mu, self.real_cov = pickle.load(f)
            self.real_cache = True
            print("Pickle load success !!!")
        else:
            print("Pickle load fail !!!")
            self.real_cache = False

        self.fid_samples_num = 10000
        print()

        physical_gpus = tf.config.experimental.list_physical_devices('GPU')
        logical_gpus = tf.config.experimental.list_logical_devices('GPU')
        print(len(physical_gpus), "Physical GPUs,", len(logical_gpus), "Logical GPUs")
        print("Each batch size : ", self.each_batch_size)
        print("Global batch size : ", self.batch_size)
        print("Target image size : ", self.img_size)
        print("Print frequency : ", self.print_freq)
        print("Save frequency : ", self.save_freq)

        print("TF Version :", tf.__version__)

    def set_optimizer_params(self, params):
        if self.lazy_regularization:
            mb_ratio = params['reg_interval'] / (params['reg_interval'] + 1)
            params['learning_rate'] = params['learning_rate'] * mb_ratio
            params['beta1'] = params['beta1'] ** mb_ratio
            params['beta2'] = params['beta2'] ** mb_ratio
        return params

    ##################################################################################
    # Model
    ##################################################################################
    def build_model(self):
        if self.phase == 'train':
            """ Input Image"""
            img_class = Image_data(self.img_size, self.g_params['z_dim'], self.g_params['labels_dim'], self.dataset_path)
            img_class.preprocess()

            dataset_num = len(img_class.train_images)
            if dataset_num > 10000:
                self.fid_samples_num = 50000
            print("Dataset number : ", dataset_num)
            print()

            dataset_slice = tf.data.Dataset.from_tensor_slices(img_class.train_images)

            dataset_iter = dataset_slice.shuffle(buffer_size=dataset_num, reshuffle_each_iteration=True).repeat()
            dataset_iter = dataset_iter.map(map_func=img_class.image_processing, num_parallel_calls=AUTOTUNE).batch(self.batch_size, drop_remainder=True)
            dataset_iter = dataset_iter.prefetch(buffer_size=AUTOTUNE)
            dataset_iter = self.strategy.experimental_distribute_dataset(dataset_iter)

            img_slice = dataset_slice.shuffle(buffer_size=dataset_num, reshuffle_each_iteration=True, seed=777)
            img_slice = img_slice.map(map_func=inception_processing, num_parallel_calls=AUTOTUNE).batch(self.batch_size, drop_remainder=False)
            img_slice = img_slice.prefetch(buffer_size=AUTOTUNE)
            self.fid_img_slice = self.strategy.experimental_distribute_dataset(img_slice)

            self.dataset_iter = iter(dataset_iter)


            """ Network """
            self.generator = CIPSskip(self.g_params, name='Generator')
            self.discriminator = Discriminator(self.d_params, name='Discriminator')
            self.g_clone = CIPSskip(self.g_params, name='Generator')
            self.inception_model = Inception_V3()

            """ Finalize model (build) """
            test_latent = np.ones((1, self.g_params['z_dim']), dtype=np.float32)
            test_labels = np.ones((1, self.g_params['labels_dim']), dtype=np.float32)
            test_images = np.ones((1, 3, self.img_size, self.img_size), dtype=np.float32)
            test_images_inception = np.ones((1, 299, 299, 3), dtype=np.float32)

            _, __ = self.generator([test_latent, test_labels], training=False)
            _ = self.discriminator([test_images, test_labels], training=False)
            _, __ = self.g_clone([test_latent, test_labels], training=False)
            _ = self.inception_model(test_images_inception)

            # Copying g_clone
            self.g_clone.set_weights(self.generator.get_weights())

            """ Optimizer """
            self.d_optimizer = tf.keras.optimizers.Adam(self.d_opt['learning_rate'],
                                                        beta_1=self.d_opt['beta1'],
                                                        beta_2=self.d_opt['beta2'],
                                                        epsilon=self.d_opt['epsilon'])
            self.g_optimizer = tf.keras.optimizers.Adam(self.g_opt['learning_rate'],
                                                        beta_1=self.g_opt['beta1'],
                                                        beta_2=self.g_opt['beta2'],
                                                        epsilon=self.g_opt['epsilon'])

            """ Checkpoint """
            self.ckpt = tf.train.Checkpoint(generator=self.generator,
                                            g_clone=self.g_clone,
                                            discriminator=self.discriminator,
                                            g_optimizer=self.g_optimizer,
                                            d_optimizer=self.d_optimizer)
            self.manager = tf.train.CheckpointManager(self.ckpt, self.checkpoint_dir, max_to_keep=2)
            self.start_iteration = 0

            if self.manager.latest_checkpoint:
                self.ckpt.restore(self.manager.latest_checkpoint).expect_partial()
                self.start_iteration = int(self.manager.latest_checkpoint.split('-')[-1])
                print('Latest checkpoint restored!!')
                print('start iteration : ', self.start_iteration)
            else:
                print('Not restoring from saved checkpoint')

        else:
            """ Test """
            """ Network """
            self.g_clone = CIPSskip(self.g_params, name='Generator')
            self.discriminator = Discriminator(self.d_params, name='Discriminator')

            """ Finalize model (build) """
            test_latent = np.ones((1, self.g_params['z_dim']), dtype=np.float32)
            test_labels = np.ones((1, self.g_params['labels_dim']), dtype=np.float32)
            test_images = np.ones((1, 3, self.img_size, self.img_size), dtype=np.float32)
            _ = self.discriminator([test_images, test_labels], training=False)
            _, __ = self.g_clone([test_latent, test_labels], training=False)

            """ Checkpoint """
            self.ckpt = tf.train.Checkpoint(g_clone=self.g_clone, discriminator=self.discriminator)
            self.manager = tf.train.CheckpointManager(self.ckpt, self.checkpoint_dir, max_to_keep=2)

            if self.manager.latest_checkpoint:
                self.ckpt.restore(self.manager.latest_checkpoint).expect_partial()
                print('Latest checkpoint restored!!')
            else:
                print('Not restoring from saved checkpoint')

    def d_train_step(self, z, real_images, labels):
        with tf.GradientTape() as d_tape:
            # forward pass
            fake_images, _ = self.generator([z, labels], training=True)
            real_scores = self.discriminator([real_images, labels], training=True)
            fake_scores = self.discriminator([fake_images, labels], training=True)

            # gan loss
            d_adv_loss = tf.math.softplus(fake_scores)
            d_adv_loss += tf.math.softplus(-real_scores)
            d_adv_loss = multi_gpu_loss(d_adv_loss, global_batch_size=self.batch_size)

            d_loss = d_adv_loss

        d_gradients = d_tape.gradient(d_loss, self.discriminator.trainable_variables)
        self.d_optimizer.apply_gradients(zip(d_gradients, self.discriminator.trainable_variables))

        return d_loss, d_adv_loss

    def d_reg_train_step(self, z, real_images, labels):
        with tf.GradientTape() as d_tape:
            # forward pass
            fake_images, _ = self.generator([z, labels], training=True)
            real_scores = self.discriminator([real_images, labels], training=True)
            fake_scores = self.discriminator([fake_images, labels], training=True)

            # gan loss
            d_adv_loss = tf.math.softplus(fake_scores)
            d_adv_loss += tf.math.softplus(-real_scores)

            # simple GP
            with tf.GradientTape() as p_tape:
                p_tape.watch([real_images, labels])
                real_loss = tf.reduce_sum(self.discriminator([real_images, labels], training=True))

            real_grads = p_tape.gradient(real_loss, real_images)
            r1_penalty = tf.reduce_sum(tf.math.square(real_grads), axis=[1, 2, 3])
            r1_penalty = tf.expand_dims(r1_penalty, axis=1)
            r1_penalty = r1_penalty * self.d_opt['reg_interval']

            # combine
            d_adv_loss += r1_penalty * (0.5 * self.r1_gamma)
            d_adv_loss = multi_gpu_loss(d_adv_loss, global_batch_size=self.batch_size)

            d_loss = d_adv_loss

        d_gradients = d_tape.gradient(d_loss, self.discriminator.trainable_variables)
        self.d_optimizer.apply_gradients(zip(d_gradients, self.discriminator.trainable_variables))

        r1_penalty = multi_gpu_loss(r1_penalty, global_batch_size=self.batch_size)

        return d_loss, d_adv_loss, r1_penalty

    def g_train_step(self, z, labels):
        with tf.GradientTape() as g_tape:
            # forward pass
            fake_images, _ = self.generator([z, labels], training=True)
            fake_scores = self.discriminator([fake_images, labels], training=True)

            # gan loss
            g_adv_loss = tf.math.softplus(-fake_scores)
            g_adv_loss = multi_gpu_loss(g_adv_loss, global_batch_size=self.batch_size)

            g_loss = g_adv_loss

        g_gradients = g_tape.gradient(g_loss, self.generator.trainable_variables)
        self.g_optimizer.apply_gradients(zip(g_gradients, self.generator.trainable_variables))

        return g_loss, g_adv_loss

    def g_reg_train_step(self, z, labels):
        with tf.GradientTape() as g_tape:
            # forward pass
            fake_images, w_broadcasted = self.generator([z, labels], training=True)
            fake_scores = self.discriminator([fake_images, labels], training=True)

            # gan loss
            g_adv_loss = tf.math.softplus(-fake_scores)

            # path length regularization
            pl_reg = self.path_regularization(pl_minibatch_shrink=self.pl_minibatch_shrink)

            # combine
            g_adv_loss += pl_reg
            g_adv_loss = multi_gpu_loss(g_adv_loss, global_batch_size=self.batch_size)

            g_loss = g_adv_loss

        g_gradients = g_tape.gradient(g_loss, self.generator.trainable_variables)
        self.g_optimizer.apply_gradients(zip(g_gradients, self.generator.trainable_variables))

        pl_reg = multi_gpu_loss(pl_reg, global_batch_size=self.batch_size)

        return g_loss, g_adv_loss, pl_reg

    def path_regularization(self, pl_minibatch_shrink=2):
        # path length regularization
        # Compute |J*y|.

        pl_minibatch = tf.maximum(1, tf.math.floordiv(self.each_batch_size, pl_minibatch_shrink))
        pl_z = tf.random.normal(shape=[pl_minibatch, self.g_params['z_dim']], dtype=tf.float32)
        pl_labels = tf.random.normal(shape=[pl_minibatch, self.g_params['labels_dim']], dtype=tf.float32)

        with tf.GradientTape() as pl_tape:
            pl_tape.watch([pl_z, pl_labels])
            pl_fake_images, pl_w_broadcasted = self.generator([pl_z, pl_labels], training=True)

            pl_noise = tf.random.normal(tf.shape(pl_fake_images), mean=0.0, stddev=1.0, dtype=tf.float32) * self.pl_denorm
            pl_noise_applied = tf.reduce_sum(pl_fake_images * pl_noise)

        pl_grads = pl_tape.gradient(pl_noise_applied, pl_w_broadcasted)
        pl_lengths = tf.math.sqrt(tf.reduce_sum(tf.math.square(pl_grads), axis=-1))

        # Track exponential moving average of |J*y|.
        pl_mean_val = self.pl_mean + self.pl_decay * (tf.reduce_mean(pl_lengths) - self.pl_mean)
        self.pl_mean.assign(pl_mean_val)

        # Calculate (|J*y|-a)^2.
        pl_penalty = tf.square(pl_lengths - self.pl_mean) * self.g_opt['reg_interval']

        # compute
        pl_reg = pl_penalty * self.pl_weight

        return pl_reg

    """ Distribute Train """
    @tf.function
    def distribute_d_train_step(self, z, real_images, labels):
        d_loss, d_adv_loss = self.strategy.run(self.d_train_step, args=(z, real_images, labels))

        d_loss = self.strategy.reduce(tf.distribute.ReduceOp.SUM, d_loss, axis=None)
        d_adv_loss = self.strategy.reduce(tf.distribute.ReduceOp.SUM, d_adv_loss, axis=None)

        return d_loss, d_adv_loss

    @tf.function
    def distribute_d_reg_train_step(self, z, real_images, labels):
        d_loss, d_adv_loss, r1_penalty = self.strategy.run(self.d_reg_train_step, args=(z, real_images, labels))

        d_loss = self.strategy.reduce(tf.distribute.ReduceOp.SUM, d_loss, axis=None)
        d_adv_loss = self.strategy.reduce(tf.distribute.ReduceOp.SUM, d_adv_loss, axis=None)
        r1_penalty = self.strategy.reduce(tf.distribute.ReduceOp.SUM, r1_penalty, axis=None)

        return d_loss, d_adv_loss, r1_penalty

    @tf.function
    def distribute_g_train_step(self, z, labels):
        g_loss, g_adv_loss = self.strategy.run(self.g_train_step, args=(z, labels))

        g_loss = self.strategy.reduce(tf.distribute.ReduceOp.SUM, g_loss, axis=None)
        g_adv_loss = self.strategy.reduce(tf.distribute.ReduceOp.SUM, g_adv_loss, axis=None)

        return g_loss, g_adv_loss

    @tf.function
    def distribute_g_reg_train_step(self, z, labels):
        g_loss, g_adv_loss, pl_reg = self.strategy.run(self.g_reg_train_step, args=(z, labels))

        g_loss = self.strategy.reduce(tf.distribute.ReduceOp.SUM, g_loss, axis=None)
        g_adv_loss = self.strategy.reduce(tf.distribute.ReduceOp.SUM, g_adv_loss, axis=None)
        pl_reg = self.strategy.reduce(tf.distribute.ReduceOp.SUM, pl_reg, axis=None)

        return g_loss, g_adv_loss, pl_reg

    def train(self):

        start_time = time.time()

        # setup tensorboards
        train_summary_writer = tf.summary.create_file_writer(self.log_dir)

        # start training
        print('max_steps: {}'.format(self.iteration))
        losses = {'g/loss': 0.0, 'd/loss': 0.0, 'r1_reg': 0.0, 'pl_reg': 0.0,
                  'g/adv_loss': 0.0,
                  'd/adv_loss': 0.0,
                  'fid': 0.0, 'best_fid': 0.0, 'best_fid_iter': 0}
        fid = 0
        best_fid = 1000
        best_fid_iter = 0
        for idx in range(self.start_iteration, self.iteration):
            iter_start_time = time.time()

            x_real, z, labels = next(self.dataset_iter)

            if idx == 0:
                g_params = self.generator.count_params()
                d_params = self.discriminator.count_params()
                print("G network parameters : ", format(g_params, ','))
                print("D network parameters : ", format(d_params, ','))
                print("Total network parameters : ", format(g_params + d_params, ','))

            # update discriminator
            # At first time, each function takes 1~2 min to make the graph.
            if (idx + 1) % self.d_opt['reg_interval'] == 0:
                d_loss, d_adv_loss, r1_reg = self.distribute_d_reg_train_step(z, x_real, labels)
                losses['r1_reg'] = np.float64(r1_reg)
            else:
                d_loss, d_adv_loss = self.distribute_d_train_step(z, x_real, labels)

            losses['d/loss'] = np.float64(d_loss)
            losses['d/adv_loss'] = np.float64(d_adv_loss)

            # update generator
            # At first time, each function takes 1~2 min to make the graph.
            if (idx + 1) % self.g_opt['reg_interval'] == 0:
                g_loss, g_adv_loss, pl_reg = self.distribute_g_reg_train_step(z, labels)
                losses['pl_reg'] = np.float64(pl_reg)
            else:
                g_loss, g_adv_loss = self.distribute_g_train_step(z, labels)

            losses['g/loss'] = np.float64(g_loss)
            losses['g/adv_loss'] = np.float64(g_adv_loss)


            # update g_clone
            self.g_clone.set_as_moving_average_of(self.generator)

            if np.mod(idx, self.save_freq) == 0 or idx == self.iteration - 1 :
                fid = self.calculate_FID()
                if fid < best_fid:
                    print("BEST FID UPDATED")
                    best_fid = fid
                    best_fid_iter = idx
                    self.manager.save(checkpoint_number=idx)

                    losses['best_fid'] = np.float64(best_fid)
                    losses['best_fid_iter'] = np.float64(best_fid_iter)
                losses['fid'] = np.float64(fid)


            with train_summary_writer.as_default():
                tf.summary.scalar('g_loss', losses['g/loss'], step=idx)
                tf.summary.scalar('g_adv_loss', losses['g/adv_loss'], step=idx)

                tf.summary.scalar('d_loss', losses['d/loss'], step=idx)
                tf.summary.scalar('d_adv_loss', losses['d/adv_loss'], step=idx)

                tf.summary.scalar('r1_reg', losses['r1_reg'], step=idx)
                tf.summary.scalar('pl_reg', losses['pl_reg'], step=idx)
                # tf.summary.histogram('w_avg', self.generator.w_avg, step=idx)

                if np.mod(idx, self.save_freq) == 0 or idx == self.iteration - 1:
                    tf.summary.scalar('fid', losses['fid'], step=idx)

            # save every self.save_freq
            # if np.mod(idx + 1, self.save_freq) == 0:
            #     self.manager.save(checkpoint_number=idx + 1)

            # save every self.print_freq
            if np.mod(idx + 1, self.print_freq) == 0:
                total_num_samples = min(self.n_samples, self.batch_size)
                partial_size = int(np.floor(np.sqrt(total_num_samples)))

                # prepare inputs
                latents = tf.random.normal(shape=(self.n_samples, self.g_params['z_dim']), dtype=tf.dtypes.float32)
                dummy_labels = tf.random.normal((self.n_samples, self.g_params['labels_dim']), dtype=tf.dtypes.float32)

                # run networks
                fake_img, _ = self.g_clone([latents, dummy_labels], truncation_psi=1.0, training=False)

                save_images(images=fake_img[:partial_size * partial_size, :, :, :],
                            size=[partial_size, partial_size],
                            image_path='./{}/fake_{:06d}.png'.format(self.sample_dir, idx + 1))

                x_real_concat = tf.concat(self.strategy.experimental_local_results(x_real), axis=0)
                self.truncation_psi_canvas(x_real_concat, path='./{}/fake_psi_{:06d}.png'.format(self.sample_dir, idx + 1))

            elapsed = time.time() - iter_start_time
            print(self.log_template.format(idx, self.iteration, elapsed,
                                           losses['d/loss'], losses['g/loss'], losses['r1_reg'], losses['pl_reg'], fid, best_fid, best_fid_iter))
        # save model for final step
        self.manager.save(checkpoint_number=self.iteration)

        print("LAST FID: ", fid)
        print("BEST FID: {}, {}".format(best_fid, best_fid_iter))
        print("Total train time: %4.4f" % (time.time() - start_time))

    @property
    def model_dir(self):
        return "{}_{}_{}_{}".format(self.model_name, self.dataset_name, self.img_size, self.config)


    def calculate_FID(self):
        @tf.function
        def gen_samples_feats(test_z, test_labels, g_clone, inception_model):
            # run networks
            fake_img, _ = g_clone([test_z, test_labels], training=False)
            fake_img = adjust_dynamic_range(fake_img, range_in=(-1.0, 1.0), range_out=(0.0, 255.0), out_dtype=tf.float32)
            fake_img = tf.transpose(fake_img, [0, 2, 3, 1])
            fake_img = tf.image.resize(fake_img, [299, 299], antialias=True, method=tf.image.ResizeMethod.BICUBIC)

            fake_img = torch_normalization(fake_img)

            feats = inception_model(fake_img)

            return feats

        @tf.function
        def get_inception_features(img, inception_model):
            feats = inception_model(img)
            return feats

        @tf.function
        def get_real_features(img, inception_model):
            feats = self.strategy.run(get_inception_features, args=(img, inception_model))
            feats = tf.concat(self.strategy.experimental_local_results(feats), axis=0)

            return feats

        @tf.function
        def get_fake_features(z, dummy_labels, g_clone, inception_model):

            feats = self.strategy.run(gen_samples_feats, args=(z, dummy_labels, g_clone, inception_model))
            feats = tf.concat(self.strategy.experimental_local_results(feats), axis=0)

            return feats

        @tf.function
        def convert_per_replica_image(nchw_per_replica_images, strategy):
            as_tensor = tf.concat(strategy.experimental_local_results(nchw_per_replica_images), axis=0)
            as_tensor = tf.transpose(as_tensor, perm=[0, 2, 3, 1])
            as_tensor = (tf.clip_by_value(as_tensor, -1.0, 1.0) + 1.0) * 127.5
            as_tensor = tf.cast(as_tensor, tf.uint8)
            as_tensor = tf.image.resize(as_tensor, [299, 299], antialias=True, method=tf.image.ResizeMethod.BICUBIC)

            return as_tensor

        if not self.real_cache:
            real_feats = tf.zeros([0, 2048])
            """ Input Image"""
            for img in self.fid_img_slice:
                feats = get_real_features(img, self.inception_model)
                real_feats = tf.concat([real_feats, feats], axis=0)
                print('real feats:', np.shape(real_feats)[0])

            self.real_mu = np.mean(real_feats, axis=0)
            self.real_cov = np.cov(real_feats, rowvar=False)

            with open('{}_mu_cov.pickle'.format(self.dataset_name), 'wb') as f:
                pickle.dump((self.real_mu, self.real_cov), f, protocol=pickle.HIGHEST_PROTOCOL)

            print('{} real pickle save !!!'.format(self.dataset_name))

            self.real_cache = True
            del real_feats

        fake_feats = tf.zeros([0, 2048])
        from tqdm import tqdm
        for begin in tqdm(range(0, self.fid_samples_num, self.batch_size)):
            z = tf.random.normal(shape=[self.each_batch_size, self.g_params['z_dim']])
            dummy_labels = tf.random.normal((self.each_batch_size, self.g_params['labels_dim']), dtype=tf.float32)

            feats = get_fake_features(z, dummy_labels, self.g_clone, self.inception_model)

            fake_feats = tf.concat([fake_feats, feats], axis=0)
            # print('fake feats:', np.shape(fake_feats)[0])

        fake_mu = np.mean(fake_feats, axis=0)
        fake_cov = np.cov(fake_feats, rowvar=False)
        del fake_feats

        # Calculate FID.
        m = np.square(fake_mu - self.real_mu).sum()
        s, _ = scipy.linalg.sqrtm(np.dot(fake_cov, self.real_cov), disp=False)  # pylint: disable=no-member
        dist = m + np.trace(fake_cov + self.real_cov - 2 * s)

        return dist


    def truncation_psi_canvas(self, real_images, path):
        # prepare inputs
        reals = real_images[:self.n_samples, :, :, :]
        latents = tf.random.normal(shape=(self.n_samples, self.g_params['z_dim']), dtype=tf.dtypes.float32)
        dummy_labels = tf.random.normal((self.n_samples, self.g_params['labels_dim']), dtype=tf.dtypes.float32)

        # run networks
        fake_images_00, _ = self.g_clone([latents, dummy_labels], truncation_psi=0.0, training=False)
        fake_images_05, _ = self.g_clone([latents, dummy_labels], truncation_psi=0.5, training=False)
        fake_images_07, _ = self.g_clone([latents, dummy_labels], truncation_psi=0.7, training=False)
        fake_images_10, _ = self.g_clone([latents, dummy_labels], truncation_psi=1.0, training=False)

        # merge on batch dimension: [4 * n_samples, 3, img_size, img_size]
        out = tf.concat([fake_images_00, fake_images_05, fake_images_07, fake_images_10], axis=0)

        # prepare for image saving: [4 * n_samples, img_size, img_size, 3]
        out = postprocess_images(out)

        # resize to save disk spaces: [4 * n_samples, size, size, 3]
        size = min(self.img_size, 256)
        out = tf.image.resize(out, size=[size, size], antialias=True, method=tf.image.ResizeMethod.BICUBIC)

        # make single image and add batch dimension for tensorboard: [1, 4 * size, n_samples * size, 3]
        out = merge_batch_images(out, size, rows=4, cols=self.n_samples)

        images = cv2.cvtColor(out.astype('uint8'), cv2.COLOR_RGB2BGR)

        return cv2.imwrite(path, images)


    def test(self):
        result_dir = os.path.join(self.result_dir, self.model_dir)
        check_folder(result_dir)

        total_num_samples = min(self.n_samples, self.batch_size)
        partial_size = int(np.floor(np.sqrt(total_num_samples)))

        from tqdm import tqdm
        for i in tqdm(range(self.n_test)):
            z = tf.random.normal(shape=[self.batch_size, self.g_params['z_dim']])
            dummy_labels = tf.random.normal((self.batch_size, self.g_params['labels_dim']), dtype=tf.float32)
            fake_img, _ = self.g_clone([z, dummy_labels], training=False)

            save_images(images=fake_img[:partial_size * partial_size, :, :, :],
                        size=[partial_size, partial_size],
                        image_path='./{}/fake_{:01d}.png'.format(result_dir, i))

    def test_70000(self):
        result_dir = os.path.join(self.result_dir, self.model_dir)
        check_folder(result_dir)

        total_num_samples = 1
        partial_size = int(np.floor(np.sqrt(total_num_samples)))

        from tqdm import tqdm
        for i in tqdm(range(70000)):
            z = tf.random.normal(shape=[1, self.g_params['z_dim']])
            dummy_labels = tf.random.normal((1, self.g_params['labels_dim']), dtype=tf.float32)
            fake_img, _ = self.g_clone([z, dummy_labels], training=False)

            save_images(images=fake_img[:partial_size * partial_size, :, :, :],
                        size=[partial_size, partial_size],
                        image_path='./{}/fake_{:01d}.png'.format(result_dir, i))

    def draw_uncurated_result_figure(self):

        result_dir = os.path.join(self.result_dir, self.model_dir, 'paper_figure')
        check_folder(result_dir)

        seed_flag = True
        lods = [0, 1, 2, 2, 3, 3]
        seed = 3291
        rows = 3
        cx = 0
        cy = 0

        if seed_flag:
            latents = tf.cast(
                np.random.RandomState(seed).normal(size=[sum(rows * 2 ** lod for lod in lods), self.g_params['z_dim']]), tf.float32)
        else:
            latents = tf.cast(np.random.normal(size=[sum(rows * 2 ** lod for lod in lods), self.g_params['z_dim']]), tf.float32)

        dummy_labels = tf.random.normal((sum(rows * 2 ** lod for lod in lods), self.g_params['labels_dim']), dtype=tf.float32)

        images, _ = self.g_clone([latents, dummy_labels], training=False)
        images = postprocess_images(images)

        canvas = PIL.Image.new('RGB', (sum(self.img_size // 2 ** lod for lod in lods), self.img_size * rows), 'white')
        image_iter = iter(list(images))

        for col, lod in enumerate(lods):
            for row in range(rows * 2 ** lod):
                image = PIL.Image.fromarray(np.uint8(next(image_iter)), 'RGB')

                image = image.crop((cx, cy, cx + self.img_size, cy + self.img_size))
                image = image.resize((self.img_size // 2 ** lod, self.img_size // 2 ** lod), PIL.Image.ANTIALIAS)
                canvas.paste(image,
                             (sum(self.img_size // 2 ** lod for lod in lods[:col]), row * self.img_size // 2 ** lod))

        canvas.save('{}/figure02-uncurated.png'.format(result_dir))

    def draw_truncation_trick_figure(self):

        result_dir = os.path.join(self.result_dir, self.model_dir, 'paper_figure')
        check_folder(result_dir)

        seed_flag = True
        seeds = [1653, 4010]
        psis = [-1, -0.7, -0.5, 0, 0.5, 0.7, 1]

        if seed_flag:
            latents = tf.cast(
                np.concatenate(list(np.random.RandomState(seed).normal(size=[1, self.g_params['z_dim']]) for seed in seeds), axis=0), tf.float32)
        else:
            latents = tf.cast(np.random.normal(size=[len(seeds), self.g_params['z_dim']]), tf.float32)

        dummy_labels = tf.random.normal((len(seeds), self.g_params['labels_dim']), dtype=tf.float32)

        fake_images_10_, _ = self.g_clone([latents, dummy_labels], truncation_psi=-1.0, training=False)
        fake_images_05_, _ = self.g_clone([latents, dummy_labels], truncation_psi=-0.5, training=False)
        fake_images_07_, _ = self.g_clone([latents, dummy_labels], truncation_psi=-0.7, training=False)
        fake_images_00, _ = self.g_clone([latents, dummy_labels], truncation_psi=0.0, training=False)
        fake_images_05, _ = self.g_clone([latents, dummy_labels], truncation_psi=0.5, training=False)
        fake_images_07, _ = self.g_clone([latents, dummy_labels], truncation_psi=0.7, training=False)
        fake_images_10, _ = self.g_clone([latents, dummy_labels], truncation_psi=1.0, training=False)

        # merge on batch dimension: [7, 3, img_size, img_size]
        col_images = list([fake_images_10_, fake_images_05_, fake_images_07_, fake_images_00, fake_images_05, fake_images_07, fake_images_10])

        img_out_size = min(self.img_size, 256)

        for i in range(len(col_images)):
            col_images[i] = postprocess_images(col_images[i])
            col_images[i] = tf.image.resize(col_images[i], size=[img_out_size, img_out_size], antialias=True, method=tf.image.ResizeMethod.BICUBIC)

        canvas = PIL.Image.new('RGB', (img_out_size * len(psis), img_out_size * len(seeds)), 'white')

        for col, col_img in enumerate(col_images):
            for row, image in enumerate(col_img):
                canvas.paste(PIL.Image.fromarray(np.uint8(image), 'RGB'),
                             (col * img_out_size, row * img_out_size))

        canvas.save('{}/figure08-truncation-trick.png'.format(result_dir))

from ops import *

##################################################################################
# Generator Layers
##################################################################################
class ToRGB(tf.keras.layers.Layer):
    def __init__(self, fmaps, **kwargs):
        super(ToRGB, self).__init__(**kwargs)
        self.fmaps = fmaps

        self.conv = ModulatedConv2D(fmaps=3, style_fmaps=fmaps, kernel=1, up=False, down=False, demodulate=False,
                                    resample_kernel=None, gain=1.0, lrmul=1.0, fused_modconv=True, name='conv')
        self.apply_bias = BiasAct(lrmul=1.0, act='linear', name='bias')

    def call(self, inputs, skip=None, training=None, mask=None):
        x, w = inputs

        x = self.conv([x, w])
        x = self.apply_bias(x)

        if skip is not None:
            x = x + skip

        return x

class StyledConv(tf.keras.layers.Layer):
    def __init__(self, fmaps, style_fmaps, kernel, resample_kernel=(1, 3, 3, 1), up=False, down=False, demodulate=True, fused_modconv=True, gain=1.0, lrmul=1.0, **kwargs):
        super(StyledConv, self).__init__(**kwargs)
        resample_kernel = list(resample_kernel)
        self.conv = ModulatedConv2D(fmaps, style_fmaps, kernel, resample_kernel, up, down, demodulate, fused_modconv, gain, lrmul)
        self.apply_noise = Noise(name='noise')
        self.apply_bias_act = BiasAct(lrmul=lrmul, act='lrelu', name='bias')

    def call(self, inputs, training=None, mask=None):
        x, y = inputs
        x = self.conv([x, y])
        x = self.apply_noise(x)
        x = self.apply_bias_act(x)

        return x

class ConLinear(tf.keras.layers.Layer):
    def __init__(self, out_ch, is_fist=False, **kwargs):
        super(ConLinear, self).__init__(**kwargs)
        in_ch = 2

        if is_fist:
            weight_initializer = tf.initializers.RandomUniform(minval=-np.sqrt(9 / in_ch), maxval=np.sqrt(9 / in_ch))
            self.conv = tf.keras.layers.Conv2D(filters=out_ch, kernel_size=1, strides=1, use_bias=True,
                                               data_format='channels_first', kernel_initializer=weight_initializer)
        else:
            weight_initializer = tf.initializers.random_uniform(minval=-np.sqrt(3 / in_ch), maxval=np.sqrt(3 / in_ch))
            self.conv = tf.keras.layers.Conv2D(filters=out_ch, kernel_size=1, strides=1, use_bias=True,
                                               data_format='channels_first', kernel_initializer=weight_initializer)

    def call(self, inputs, training=None, mask=None):
        x = self.conv(inputs)
        return x

class LFF(tf.keras.layers.Layer):
    def __init__(self, hidden_size, **kwargs):
        super(LFF, self).__init__(**kwargs)

        self.ffm = ConLinear(hidden_size, is_fist=True)

    def call(self, inputs, training=None, mask=None):
        x = self.ffm(inputs)
        x = tf.sin(x)

        return x

class ConstantInput(tf.keras.layers.Layer):
    def __init__(self, channel, size=4, **kwargs):
        super(ConstantInput, self).__init__(**kwargs)

        const_init = tf.random.normal(shape=(1, channel, size, size), mean=0.0, stddev=1.0)
        self.const = tf.Variable(const_init, name='const', trainable=True)

    def call(self, inputs, training=None, mask=None):
        batch = inputs.shape[0]
        x = tf.tile(self.const, multiples=[batch, 1, 1, 1])

        return x

##################################################################################
# Discriminator Layers
##################################################################################
class FromRGB(tf.keras.layers.Layer):
    def __init__(self, fmaps, **kwargs):
        super(FromRGB, self).__init__(**kwargs)
        self.fmaps = fmaps

        self.conv = Conv2D(fmaps=self.fmaps, kernel=1, up=False, down=False,
                           resample_kernel=None, gain=1.0, lrmul=1.0, name='conv')
        self.apply_bias_act = BiasAct(lrmul=1.0, act='lrelu', name='bias')

    def call(self, inputs, training=None, mask=None):
        y = self.conv(inputs)
        y = self.apply_bias_act(y)
        return y


class DiscriminatorBlock(tf.keras.layers.Layer):
    def __init__(self, n_f0, n_f1, **kwargs):
        super(DiscriminatorBlock, self).__init__(**kwargs)
        self.gain = 1.0
        self.lrmul = 1.0
        self.n_f0 = n_f0
        self.n_f1 = n_f1
        self.resnet_scale = 1. / tf.sqrt(2.)

        # conv_0
        self.conv_0 = Conv2D(fmaps=self.n_f0, kernel=3, up=False, down=False,
                             resample_kernel=None, gain=self.gain, lrmul=self.lrmul, name='conv_0')
        self.apply_bias_act_0 = BiasAct(lrmul=self.lrmul, act='lrelu', name='bias_0')

        # conv_1 down
        self.conv_1 = Conv2D(fmaps=self.n_f1, kernel=3, up=False, down=True,
                             resample_kernel=[1, 3, 3, 1], gain=self.gain, lrmul=self.lrmul, name='conv_1')
        self.apply_bias_act_1 = BiasAct(lrmul=self.lrmul, act='lrelu', name='bias_1')

        # resnet skip
        self.conv_skip = Conv2D(fmaps=self.n_f1, kernel=1, up=False, down=True,
                                resample_kernel=[1, 3, 3, 1], gain=self.gain, lrmul=self.lrmul, name='skip')

    def call(self, inputs, training=None, mask=None):
        x = inputs
        residual = x

        # conv0
        x = self.conv_0(x)
        x = self.apply_bias_act_0(x)

        # conv1 down
        x = self.conv_1(x)
        x = self.apply_bias_act_1(x)

        # resnet skip
        residual = self.conv_skip(residual)
        x = (x + residual) * self.resnet_scale
        return x

class DiscriminatorLastBlock(tf.keras.layers.Layer):
    def __init__(self, n_f0, n_f1, **kwargs):
        super(DiscriminatorLastBlock, self).__init__(**kwargs)
        self.gain = 1.0
        self.lrmul = 1.0
        self.n_f0 = n_f0
        self.n_f1 = n_f1

        self.minibatch_std = MinibatchStd(group_size=4, num_new_features=1, name='minibatchstd')

        # conv_0
        self.conv_0 = Conv2D(fmaps=self.n_f0, kernel=3, up=False, down=False,
                             resample_kernel=None, gain=self.gain, lrmul=self.lrmul, name='conv_0')
        self.apply_bias_act_0 = BiasAct(lrmul=self.lrmul, act='lrelu', name='bias_0')

        # dense_1
        self.dense_1 = Dense(self.n_f1, gain=self.gain, lrmul=self.lrmul, name='dense_1')
        self.apply_bias_act_1 = BiasAct(lrmul=self.lrmul, act='lrelu', name='bias_1')

    def call(self, x, training=None, mask=None):
        x = self.minibatch_std(x)

        # conv_0
        x = self.conv_0(x)
        x = self.apply_bias_act_0(x)

        # dense_1
        x = self.dense_1(x)
        x = self.apply_bias_act_1(x)
        return x
# Copyright (c) 2019, NVIDIA Corporation. All rights reserved.
#
# This work is made available under the Nvidia Source Code License-NC.
# To view a copy of this license, visit
# https://nvlabs.github.io/stylegan2/license.html

"""TensorFlow custom ops builder.
"""

import os
import re
import uuid
import hashlib
import tempfile
import shutil
import tensorflow as tf
from tensorflow.python.client import device_lib # pylint: disable=no-name-in-module

#----------------------------------------------------------------------------
# Global options.

cuda_cache_path = os.path.join(os.path.dirname(__file__), '_cudacache')
cuda_cache_version_tag = 'v1'
do_not_hash_included_headers = False # Speed up compilation by assuming that headers included by the CUDA code never change. Unsafe!
verbose = True # Print status messages to stdout.

compiler_bindir_search_path = [
    'C:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC/14.14.26428/bin/Hostx64/x64',
    'C:/Program Files (x86)/Microsoft Visual Studio/2019/Community/VC/Tools/MSVC/14.23.28105/bin/Hostx64/x64',
    'C:/Program Files (x86)/Microsoft Visual Studio 14.0/vc/bin',
]

#----------------------------------------------------------------------------
# Internal helper funcs.

def _find_compiler_bindir():
    for compiler_path in compiler_bindir_search_path:
        if os.path.isdir(compiler_path):
            return compiler_path
    return None

def _get_compute_cap(device):
    caps_str = device.physical_device_desc
    m = re.search('compute capability: (\\d+).(\\d+)', caps_str)
    major = m.group(1)
    minor = m.group(2)
    return (major, minor)

def _get_cuda_gpu_arch_string():
    gpus = [x for x in device_lib.list_local_devices() if x.device_type == 'GPU']
    if len(gpus) == 0:
        raise RuntimeError('No GPU devices found')
    (major, minor) = _get_compute_cap(gpus[0])
    return 'sm_%s%s' % (major, minor)

def _run_cmd(cmd):
    with os.popen(cmd) as pipe:
        output = pipe.read()
        status = pipe.close()
    if status is not None:
        raise RuntimeError('NVCC returned an error. See below for full command line and output log:\n\n%s\n\n%s' % (cmd, output))

def _prepare_nvcc_cli(opts):
    cmd = 'nvcc --std=c++11 -DNDEBUG ' + opts.strip()
    cmd += ' --disable-warnings'
    cmd += ' --include-path "%s"' % tf.sysconfig.get_include()
    cmd += ' --include-path "%s"' % os.path.join(tf.sysconfig.get_include(), 'external', 'protobuf_archive', 'src')
    cmd += ' --include-path "%s"' % os.path.join(tf.sysconfig.get_include(), 'external', 'com_google_absl')
    cmd += ' --include-path "%s"' % os.path.join(tf.sysconfig.get_include(), 'external', 'eigen_archive')

    compiler_bindir = _find_compiler_bindir()
    if compiler_bindir is None:
        # Require that _find_compiler_bindir succeeds on Windows.  Allow
        # nvcc to use whatever is the default on Linux.
        if os.name == 'nt':
            raise RuntimeError('Could not find MSVC/GCC/CLANG installation on this computer. Check compiler_bindir_search_path list in "%s".' % __file__)
    else:
        cmd += ' --compiler-bindir "%s"' % compiler_bindir
    cmd += ' 2>&1'
    return cmd

#----------------------------------------------------------------------------
# Main entry point.

_plugin_cache = dict()

def get_plugin(cuda_file):
    cuda_file_base = os.path.basename(cuda_file)
    cuda_file_name, cuda_file_ext = os.path.splitext(cuda_file_base)

    # Already in cache?
    if cuda_file in _plugin_cache:
        return _plugin_cache[cuda_file]

    # Setup plugin.
    if verbose:
        print('Setting up TensorFlow plugin "%s": ' % cuda_file_base, end='', flush=True)
    try:
        # Hash CUDA source.
        md5 = hashlib.md5()
        with open(cuda_file, 'rb') as f:
            md5.update(f.read())
        md5.update(b'\n')

        # Hash headers included by the CUDA code by running it through the preprocessor.
        if not do_not_hash_included_headers:
            if verbose:
                print('Preprocessing... ', end='', flush=True)
            with tempfile.TemporaryDirectory() as tmp_dir:
                tmp_file = os.path.join(tmp_dir, cuda_file_name + '_tmp' + cuda_file_ext)
                _run_cmd(_prepare_nvcc_cli('"%s" --preprocess -o "%s" --keep --keep-dir "%s"' % (cuda_file, tmp_file, tmp_dir)))
                with open(tmp_file, 'rb') as f:
                    bad_file_str = ('"' + cuda_file.replace('\\', '/') + '"').encode('utf-8') # __FILE__ in error check macros
                    good_file_str = ('"' + cuda_file_base + '"').encode('utf-8')
                    for ln in f:
                        if not ln.startswith(b'# ') and not ln.startswith(b'#line '): # ignore line number pragmas
                            ln = ln.replace(bad_file_str, good_file_str)
                            md5.update(ln)
                    md5.update(b'\n')

        # Select compiler options.
        compile_opts = ''
        if os.name == 'nt':
            compile_opts += '"%s"' % os.path.join(tf.sysconfig.get_lib(), 'python', '_pywrap_tensorflow_internal.lib')
        elif os.name == 'posix':
            compile_opts += '"%s"' % os.path.join(tf.sysconfig.get_lib(), 'python', '_pywrap_tensorflow_internal.so')
            compile_opts += ' --compiler-options \'-fPIC -D_GLIBCXX_USE_CXX11_ABI=0\''
        else:
            assert False # not Windows or Linux, w00t?
        compile_opts += ' --gpu-architecture=%s' % _get_cuda_gpu_arch_string()
        compile_opts += ' --use_fast_math'
        nvcc_cmd = _prepare_nvcc_cli(compile_opts)

        # Hash build configuration.
        md5.update(('nvcc_cmd: ' + nvcc_cmd).encode('utf-8') + b'\n')
        md5.update(('tf.VERSION: ' + tf.version.VERSION).encode('utf-8') + b'\n')
        md5.update(('cuda_cache_version_tag: ' + cuda_cache_version_tag).encode('utf-8') + b'\n')

        # Compile if not already compiled.
        bin_file_ext = '.dll' if os.name == 'nt' else '.so'
        bin_file = os.path.join(cuda_cache_path, cuda_file_name + '_' + md5.hexdigest() + bin_file_ext)
        if not os.path.isfile(bin_file):
            if verbose:
                print('Compiling... ', end='', flush=True)
            with tempfile.TemporaryDirectory() as tmp_dir:
                tmp_file = os.path.join(tmp_dir, cuda_file_name + '_tmp' + bin_file_ext)
                _run_cmd(nvcc_cmd + ' "%s" --shared -o "%s" --keep --keep-dir "%s"' % (cuda_file, tmp_file, tmp_dir))
                os.makedirs(cuda_cache_path, exist_ok=True)
                intermediate_file = os.path.join(cuda_cache_path, cuda_file_name + '_' + uuid.uuid4().hex + '_tmp' + bin_file_ext)
                shutil.copyfile(tmp_file, intermediate_file)
                os.rename(intermediate_file, bin_file) # atomic

        # Load.
        if verbose:
            print('Loading... ', end='', flush=True)
        plugin = tf.load_op_library(bin_file)

        # Add to cache.
        _plugin_cache[cuda_file] = plugin
        if verbose:
            print('Done.', flush=True)
        return plugin

    except:
        if verbose:
            print('Failed!', flush=True)
        raise

#----------------------------------------------------------------------------

import os
import numpy as np
import tensorflow as tf
from cuda import custom_ops


def _get_plugin():
    loc = os.path.dirname(os.path.abspath(__file__))
    cu_fn = 'upfirdn_2d.cu'
    return custom_ops.get_plugin(os.path.join(loc, cu_fn))


def _setup_kernel(k):
    k = np.asarray(k, dtype=np.float32)
    if k.ndim == 1:
        k = np.outer(k, k)
    k /= np.sum(k)
    assert k.ndim == 2
    assert k.shape[0] == k.shape[1]
    return k


def compute_paddings(resample_kernel, convW, up, down, is_conv, factor=2, gain=1):
    assert not (up and down)

    k = [1] * factor if resample_kernel is None else resample_kernel
    if up:
        k = _setup_kernel(k) * (gain * (factor ** 2))
        if is_conv:
            p = (k.shape[0] - factor) - (convW - 1)
            pad0 = (p + 1) // 2 + factor - 1
            pad1 = p // 2 + 1
        else:
            p = k.shape[0] - factor
            pad0 = (p + 1) // 2 + factor - 1
            pad1 = p // 2
    elif down:
        k = _setup_kernel(k) * gain
        if is_conv:
            p = (k.shape[0] - factor) + (convW - 1)
            pad0 = (p + 1) // 2
            pad1 = p // 2
        else:
            p = k.shape[0] - factor
            pad0 = (p + 1) // 2
            pad1 = p // 2
    else:
        k = resample_kernel
        pad0, pad1 = 0, 0
    return k, pad0, pad1


def upsample_2d(x, pad0, pad1, k, factor=2):
    assert isinstance(factor, int) and factor >= 1
    x_res = x.shape[2]
    return _simple_upfirdn_2d(x, x_res, k, up=factor, pad0=pad0, pad1=pad1)


def downsample_2d(x, pad0, pad1, k, factor=2):
    assert isinstance(factor, int) and factor >= 1
    x_res = x.shape[2]
    return _simple_upfirdn_2d(x, x_res, k, down=factor, pad0=pad0, pad1=pad1)


def upsample_conv_2d(x, w, convH, convW, pad0, pad1, k, factor=2):
    assert isinstance(factor, int) and factor >= 1

    x_res = x.shape[2]
    # Check weight shape.
    w = tf.convert_to_tensor(w)
    assert w.shape.rank == 4
    # convH = w.shape[0]
    # convW = w.shape[1]
    inC = tf.shape(w)[2]
    outC = tf.shape(w)[3]
    assert convW == convH

    # Determine data dimensions.
    stride = [1, 1, factor, factor]
    output_shape = [tf.shape(x)[0], outC, (x_res - 1) * factor + convH, (x_res - 1) * factor + convW]
    num_groups = tf.shape(x)[1] // inC

    # Transpose weights.
    w = tf.reshape(w, [convH, convW, inC, num_groups, -1])
    w = tf.transpose(w[::-1, ::-1], [0, 1, 4, 3, 2])
    w = tf.reshape(w, [convH, convW, -1, num_groups * inC])

    # Execute.
    x = tf.nn.conv2d_transpose(x, w, output_shape=output_shape, strides=stride, padding='VALID', data_format='NCHW')
    new_x_res = output_shape[2]
    return _simple_upfirdn_2d(x, new_x_res, k, pad0=pad0, pad1=pad1)


def conv_downsample_2d(x, w, convH, convW, pad0, pad1, k, factor=2):
    assert isinstance(factor, int) and factor >= 1
    x_res = x.shape[2]
    w = tf.convert_to_tensor(w)
    # convH, convW, _inC, _outC = w.shape.as_list()
    assert convW == convH

    s = [1, 1, factor, factor]
    x = _simple_upfirdn_2d(x, x_res, k, pad0=pad0, pad1=pad1)
    return tf.nn.conv2d(x, w, strides=s, padding='VALID', data_format='NCHW')


def _simple_upfirdn_2d(x, x_res, k, up=1, down=1, pad0=0, pad1=0):
    assert x.shape.rank == 4
    y = x
    y = tf.reshape(y, [-1, x_res, x_res, 1])
    y = upfirdn_2d_cuda(y, k, upx=up, upy=up, downx=down, downy=down, padx0=pad0, padx1=pad1, pady0=pad0, pady1=pad1)
    y = tf.reshape(y, [-1, tf.shape(x)[1], tf.shape(y)[1], tf.shape(y)[2]])
    return y


def upfirdn_2d_cuda(x, k, upx, upy, downx, downy, padx0, padx1, pady0, pady1):
    """Fast CUDA implementation of `upfirdn_2d()` using custom ops."""

    x = tf.convert_to_tensor(x)
    k = np.asarray(k, dtype=np.float32)
    majorDim, inH, inW, minorDim = x.shape.as_list()
    kernelH, kernelW = k.shape
    assert inW >= 1 and inH >= 1
    assert kernelW >= 1 and kernelH >= 1
    assert isinstance(upx, int) and isinstance(upy, int)
    assert isinstance(downx, int) and isinstance(downy, int)
    assert isinstance(padx0, int) and isinstance(padx1, int)
    assert isinstance(pady0, int) and isinstance(pady1, int)

    outW = (inW * upx + padx0 + padx1 - kernelW) // downx + 1
    outH = (inH * upy + pady0 + pady1 - kernelH) // downy + 1
    assert outW >= 1 and outH >= 1

    kc = tf.constant(k, dtype=x.dtype)
    gkc = tf.constant(k[::-1, ::-1], dtype=x.dtype)
    gpadx0 = kernelW - padx0 - 1
    gpady0 = kernelH - pady0 - 1
    gpadx1 = inW * upx - outW * downx + padx0 - upx + 1
    gpady1 = inH * upy - outH * downy + pady0 - upy + 1

    @tf.custom_gradient
    def func(x):
        y = _get_plugin().up_fir_dn2d(x=x, k=kc, upx=upx, upy=upy, downx=downx, downy=downy, padx0=padx0, padx1=padx1, pady0=pady0, pady1=pady1)
        y.set_shape([majorDim, outH, outW, minorDim])
        @tf.custom_gradient
        def grad(dy):
            dx = _get_plugin().up_fir_dn2d(x=dy, k=gkc, upx=downx, upy=downy, downx=upx, downy=upy, padx0=gpadx0, padx1=gpadx1, pady0=gpady0, pady1=gpady1)
            dx.set_shape([majorDim, inH, inW, minorDim])
            return dx, func
        return y, grad
    return func(x)

# Copyright (c) 2019, NVIDIA Corporation. All rights reserved.
#
# This work is made available under the Nvidia Source Code License-NC.
# To view a copy of this license, visit
# https://nvlabs.github.io/stylegan2/license.html

"""Custom TensorFlow ops for efficient bias and activation."""

import os
import numpy as np
import tensorflow as tf
from cuda import custom_ops
from utils import EasyDict

def _get_plugin():
    return custom_ops.get_plugin(os.path.splitext(__file__)[0] + '.cu')

#----------------------------------------------------------------------------

activation_funcs = {
    'linear':   EasyDict(func=lambda x, **_:        x,                          def_alpha=None, def_gain=1.0,           cuda_idx=1, ref='y', zero_2nd_grad=True),
    'relu':     EasyDict(func=lambda x, **_:        tf.nn.relu(x),              def_alpha=None, def_gain=np.sqrt(2),    cuda_idx=2, ref='y', zero_2nd_grad=True),
    'lrelu':    EasyDict(func=lambda x, alpha, **_: tf.nn.leaky_relu(x, alpha), def_alpha=0.2,  def_gain=np.sqrt(2),    cuda_idx=3, ref='y', zero_2nd_grad=True),
    'tanh':     EasyDict(func=lambda x, **_:        tf.nn.tanh(x),              def_alpha=None, def_gain=1.0,           cuda_idx=4, ref='y', zero_2nd_grad=False),
    'sigmoid':  EasyDict(func=lambda x, **_:        tf.nn.sigmoid(x),           def_alpha=None, def_gain=1.0,           cuda_idx=5, ref='y', zero_2nd_grad=False),
    'elu':      EasyDict(func=lambda x, **_:        tf.nn.elu(x),               def_alpha=None, def_gain=1.0,           cuda_idx=6, ref='y', zero_2nd_grad=False),
    'selu':     EasyDict(func=lambda x, **_:        tf.nn.selu(x),              def_alpha=None, def_gain=1.0,           cuda_idx=7, ref='y', zero_2nd_grad=False),
    'softplus': EasyDict(func=lambda x, **_:        tf.nn.softplus(x),          def_alpha=None, def_gain=1.0,           cuda_idx=8, ref='y', zero_2nd_grad=False),
    'swish':    EasyDict(func=lambda x, **_:        tf.nn.sigmoid(x) * x,       def_alpha=None, def_gain=np.sqrt(2),    cuda_idx=9, ref='x', zero_2nd_grad=False),
}

#----------------------------------------------------------------------------

def fused_bias_act(x, b=None, axis=1, act='linear', alpha=None, gain=None, impl='cuda'):
    r"""Fused bias and activation function.

    Adds bias `b` to activation tensor `x`, evaluates activation function `act`,
    and scales the result by `gain`. Each of the steps is optional. In most cases,
    the fused op is considerably more efficient than performing the same calculation
    using standard TensorFlow ops. It supports first and second order gradients,
    but not third order gradients.

    Args:
        x:      Input activation tensor. Can have any shape, but if `b` is defined, the
                dimension corresponding to `axis`, as well as the rank, must be known.
        b:      Bias vector, or `None` to disable. Must be a 1D tensor of the same type
                as `x`. The shape must be known, and it must match the dimension of `x`
                corresponding to `axis`.
        axis:   The dimension in `x` corresponding to the elements of `b`.
                The value of `axis` is ignored if `b` is not specified.
        act:    Name of the activation function to evaluate, or `"linear"` to disable.
                Can be e.g. `"relu"`, `"lrelu"`, `"tanh"`, `"sigmoid"`, `"swish"`, etc.
                See `activation_funcs` for a full list. `None` is not allowed.
        alpha:  Shape parameter for the activation function, or `None` to use the default.
        gain:   Scaling factor for the output tensor, or `None` to use default.
                See `activation_funcs` for the default scaling of each activation function.
                If unsure, consider specifying `1.0`.
        impl:   Name of the implementation to use. Can be `"ref"` or `"cuda"` (default).

    Returns:
        Tensor of the same shape and datatype as `x`.
    """

    impl_dict = {
        'ref':  _fused_bias_act_ref,
        'cuda': _fused_bias_act_cuda,
    }
    return impl_dict[impl](x=x, b=b, axis=axis, act=act, alpha=alpha, gain=gain)

#----------------------------------------------------------------------------

def _fused_bias_act_ref(x, b, axis, act, alpha, gain):
    """Slow reference implementation of `fused_bias_act()` using standard TensorFlow ops."""

    # Validate arguments.
    x = tf.convert_to_tensor(x)
    b = tf.convert_to_tensor(b) if b is not None else tf.constant([], dtype=x.dtype)
    act_spec = activation_funcs[act]
    assert b.shape.rank == 1 and (b.shape[0] == 0 or b.shape[0] == x.shape[axis])
    assert b.shape[0] == 0 or 0 <= axis < x.shape.rank
    if alpha is None:
        alpha = act_spec.def_alpha
    if gain is None:
        gain = act_spec.def_gain

    # Add bias.
    if b.shape[0] != 0:
        x += tf.reshape(b, [-1 if i == axis else 1 for i in range(x.shape.rank)])

    # Evaluate activation function.
    x = act_spec.func(x, alpha=alpha)

    # Scale by gain.
    if gain != 1:
        x *= gain
    return x

#----------------------------------------------------------------------------

def _fused_bias_act_cuda(x, b, axis, act, alpha, gain):
    """Fast CUDA implementation of `fused_bias_act()` using custom ops."""

    # Validate arguments.
    x = tf.convert_to_tensor(x)
    empty_tensor = tf.constant([], dtype=x.dtype)
    b = tf.convert_to_tensor(b) if b is not None else empty_tensor
    act_spec = activation_funcs[act]
    assert b.shape.rank == 1 and (b.shape[0] == 0 or b.shape[0] == x.shape[axis])
    assert b.shape[0] == 0 or 0 <= axis < x.shape.rank
    if alpha is None:
        alpha = act_spec.def_alpha
    if gain is None:
        gain = act_spec.def_gain

    # Special cases.
    if act == 'linear' and b is None and gain == 1.0:
        return x
    if act_spec.cuda_idx is None:
        return _fused_bias_act_ref(x=x, b=b, axis=axis, act=act, alpha=alpha, gain=gain)

    # CUDA kernel.
    cuda_kernel = _get_plugin().fused_bias_act
    cuda_kwargs = dict(axis=axis, act=act_spec.cuda_idx, alpha=alpha, gain=gain)

    # Forward pass: y = func(x, b).
    def func_y(x, b):
        y = cuda_kernel(x=x, b=b, ref=empty_tensor, grad=0, **cuda_kwargs)
        y.set_shape(x.shape)
        return y

    # Backward pass: dx, db = grad(dy, x, y)
    def grad_dx(dy, x, y):
        ref = {'x': x, 'y': y}[act_spec.ref]
        dx = cuda_kernel(x=dy, b=empty_tensor, ref=ref, grad=1, **cuda_kwargs)
        dx.set_shape(x.shape)
        return dx
    def grad_db(dx):
        if b.shape[0] == 0:
            return empty_tensor
        db = dx
        if axis < x.shape.rank - 1:
            db = tf.reduce_sum(db, list(range(axis + 1, x.shape.rank)))
        if axis > 0:
            db = tf.reduce_sum(db, list(range(axis)))
        db.set_shape(b.shape)
        return db

    # Second order gradients: d_dy, d_x = grad2(d_dx, d_db, x, y)
    def grad2_d_dy(d_dx, d_db, x, y):
        ref = {'x': x, 'y': y}[act_spec.ref]
        d_dy = cuda_kernel(x=d_dx, b=d_db, ref=ref, grad=1, **cuda_kwargs)
        d_dy.set_shape(x.shape)
        return d_dy
    def grad2_d_x(d_dx, d_db, x, y):
        ref = {'x': x, 'y': y}[act_spec.ref]
        d_x = cuda_kernel(x=d_dx, b=d_db, ref=ref, grad=2, **cuda_kwargs)
        d_x.set_shape(x.shape)
        return d_x

    # Fast version for piecewise-linear activation funcs.
    @tf.custom_gradient
    def func_zero_2nd_grad(x, b):
        y = func_y(x, b)
        @tf.custom_gradient
        def grad(dy):
            dx = grad_dx(dy, x, y)
            db = grad_db(dx)
            def grad2(d_dx, d_db):
                d_dy = grad2_d_dy(d_dx, d_db, x, y)
                return d_dy
            return (dx, db), grad2
        return y, grad

    # Slow version for general activation funcs.
    @tf.custom_gradient
    def func_nonzero_2nd_grad(x, b):
        y = func_y(x, b)
        def grad_wrap(dy):
            @tf.custom_gradient
            def grad_impl(dy, x):
                dx = grad_dx(dy, x, y)
                db = grad_db(dx)
                def grad2(d_dx, d_db):
                    d_dy = grad2_d_dy(d_dx, d_db, x, y)
                    d_x = grad2_d_x(d_dx, d_db, x, y)
                    return d_dy, d_x
                return (dx, db), grad2
            return grad_impl(dy, x)
        return y, grad_wrap

    # Which version to use?
    if act_spec.zero_2nd_grad:
        return func_zero_2nd_grad(x, b)
    return func_nonzero_2nd_grad(x, b)

#----------------------------------------------------------------------------

